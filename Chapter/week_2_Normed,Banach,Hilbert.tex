\documentclass{article}
\usepackage[utf8]{inputenc}
\input{commands}

\title{Week 2}

\begin{document}
\maketitle


\section{Banach Space}\label{banach space def}%\plz


Banach space is the one of the core concepts of functional analysis.  It is a special type of {\bf vector space}, with a {\bf norm} working on the space as well as the property that every {\bf Cauchy sequence converges} in the space.\\
One should pay attention that a considerable portion of content in this chapter is not based on completeness but only requires a norm on the space. However, it is obvious that they can be applied to Banach spaces and most importantly, these results do relate themselves to Banach spaces.


\subsection{Definitions}

\begin{definition}[Normed vector space]\rm\label{definition of norm}\nextline
	A normed vector space $\mathbf{X}$ is a vector space (over $\mathbb{F}$, usually $\mathbb{C}$ or $\mathbb{R}$), equipped with a norm function $|| \cdot||:\mathbf{X}\times \mathbf{X}\xrightarrow{}{\mathbb{R}}$ satisfying following:

	\begin{itemize}
		\item $||x||\geq0,\,\forall x\in\mathbf{X}$
		\item $||x||=0$ if and only if $x=0$
		\item $||ax||=a||x||,\, \forall x\in\mathbf{X},\, \forall a\in\mathbb{F}$
		\item $||x+y||\leq||x||+||y||,\forall x,y\in\mathbf{X}$
	\end{itemize}
	A normed vector  space is also called a normed linear space.
\end{definition}


\begin{definition}[Cauchy Sequence]\rm\nextline
	\label{Cauchy Sequence}
	A Cauchy sequence in a normed vector space $V$ is a sequence $\{a_n\}_1^\infty$, where each $a_n\in V$, satisfying the following:
	$\epsilon>0,\exists\, N\in\mathbb{N}\,\,s.t.\,\,
		\forall\, m,n>N, ||a_m-a_n||<\epsilon$

\end{definition}

\begin{definition}[Convergence]\rm\nextline
	A sequence $\{a_n\}_1^\infty$in a normed vector space $V$ is convergent if
	$\exists a\in V$ s.t.
	$\forall \epsilon>0, \exists N>0 s.t. \forall n>N, ||a_n-a||<\epsilon$.

\end{definition}

\begin{definition}[Completeness]\rm\nextline
	A normed vector space is complete if every \href{Cauchy Sequence}{Cauchy Sequence} converges to a point in the space.

\end{definition}

\begin{theorem}[Every metric space can be completed]\rm\nextline
	Result is put \hyperref[completion of metric space]{\color {red} here} in appendix.
\end{theorem}
\begin{definition}[Banach space]\rm\nextline
	A Banach space is a complete normed vector space.
\end{definition}


%One might ask, is it possible for a Cauchy sequence in a normed vector space not converge??



\subsection{Examples}
\begin{example}[$\mathbb{R}^n$]\rm\nextline
	Our acquainted three-dimensional vector space over $\mathbb{R}$  is a Banach space under the standard vector norm, this is the case when $n=3$. This is a trivial result, since such norm gives the "length" of a vector, and a Cauchy sequence of vectors indicates that 'endpoints' of vectors come arbitrarily close. It's easy to prove that such a sequence converges to a three-dimensional vector. In fact, any n-dimensional  vector space over $\mathbb R$ is a Banach space.
\end{example}

\begin{example}[Real valued functions]\rm\nextline
	The set of all real-valued function on [0,1] with norm $\|f\|=\max_{t \in [0,1]} |f(t)|$
	is a Banach space. To verify this (thoroughly) we shall first show that this is a vector space. This is trivial since sum and and scalar multiplication of a real-valued function is also real-valued. Then we should show that this function is indeed a norm. Finally, we should check that every Cauchy sequence under this norm is convergent. Intuitively, this norm gives the 'maximal pointwise difference' between two functions, hence if a sequence is Cauchy, the 'maximal pointwise difference' converges to zero. Rigorous proof is left to readers.
\end{example}

\begin{example}[Continuous function under supremum norm]\rm\nextline
	Consider $C[0,1]$, set of continuous real-valued defined on $[0,1]$ with supremum norm:
	$$\|f\|_\infty=\sup_{t \in [0,1]} |f(t)|$$ This is a Banach space (why?). Now a relevant example is $C^1[0,1]$,set of complex-valued function defined on $[0,1]$ with continuous first derivative. Unfortunately this is not a Banach space under supremum norm, however, if we equip the space with a new norm: $\|f\|=\|f\|_\infty+\|f'\|_\infty$, we end up having a Banach space.\hfill
\end{example}

\begin{example}[L-p spaces]\rm\label{lp space1}\nextline
	L-p spaces are function spaces with finite $p-norm$. Let $(S,\Sigma,\mu)$ be measure space, $p\in[1,+\infty]$. L-p space consists of functions $S\xrightarrow{}\mathbb{C}$ with $p-norm$:
	$$\norm{f}_p\equiv\left(\int_S|f|^p \,d\mu\right)^\frac{1}{p}<\infty$$
	It is not obvious how $p-norm$ really gives a norm, the difficulties lie in the part of proving the triangular inequality. In the specific background of L-p spaces, the inequality is precisely \textit{Minkowski's inequality}. Detailed material on Hölder's inequality and Minkowski's inequality are put in appendix.
\end{example}


\subsection{Finite dimensional Normed space}\label{finite dimensional Banach}  

Bare in mind that in this section we do not assume that spaces are complete, so please pay attention which results are based on completeness. However, we shall see that all finite dimensional vector      space over complete fields are complete.  

Some main theorems to focus on in this section, presented in plain language:
\begin{itemize}
	\item All finite dimensional vector space over a complete field are complete
	\item All norms on finite dimensional vector spaces are equivalent
	\item $Bounded+Closed=Compact$ if and only if dimension is finite.
\end{itemize}
Reference: \href{https://math.mit.edu/~stevenj/18.335/norm-equivalence.pdf}{norm-equivalence note}

\subsubsection{Equivalence of Norms and topology}
There are many norms. Some acts similarly, some acts differently. One may have seen different types of matrix norm, for example, Frobinius norm and operator norm. Computational mathematicians don't seem to care about this, why is it? Maybe they don't make much difference!
\begin{definition}[Equivalence of Norm]\label{equivalent norms}\rm\nextline
	Let $X$ be a vector space. Two norms $\norm{\cdot}_a$, $\norm{\cdot}_b$ on $X$ are {\bf equivalent} if their exists $m,n>0$ satisfying following equation:
	$$
		m\norm{x}_a\leq \norm{x}_b\leq M\norm{x}_a,\,\,\forall x\in X
	$$
\end{definition}

\begin{theorem}[Equivalence of finite dimensional norms]\rm\nextline
	Let $X$ be a finite dimensional vector space, then any two norms $\norm{\cdot}_a$ and $\norm{\cdot}_b$ are equivalent.\\
	\prf The proof are divided into four steps:
	\begin{itemize}
		\item Showing that equivalence of norm is transitive
		\item Showing that equivalence of equivalence on unit sphere implies equivalence on $X$
		\item Showing that any norm is continuous with respect to $\norm{\cdot}_1$
		\item Showing that any norm is equivalent to $\norm{x}_1\equiv\sum_{s=1}^n |x_s|$
	\end{itemize}
	\begin{pf}{STEP I}{}
		Let $\norm{\cdot}_a$ be equivalent to $\norm{\cdot}_b$ and $\norm{\cdot}_b$ equivalent to $\norm{\cdot}_c$.
		Then $\exists m_1,m_2,M_1,M_2>0$ with
		\begin{equation}
			\begin{split}\nonumber
				&m_1\norm{x}_a\leq \norm{x}_b\leq M_1\norm{x}_a,\,\,\forall x\in X\\
				&m_2\norm{x}_b\leq \norm{x}_c\leq M_2\norm{x}_b,\,\,\forall x\in X
			\end{split}
		\end{equation}
		Then
		\begin{equation}
			\begin{split}\nonumber
				&m_1m_2\norm{x}_a\leq m_2\norm{x}_b\leq \norm{x}_c,\,\,\forall x\in X\\
				&\norm{x}_c\leq M_2\norm{x}_b\leq M_1M_2\norm{x}_c\,\,\forall x\in X
			\end{split}
		\end{equation}
		Which gives $m_1m_2\norm{x}_a\leq\norm{c}\leq M_1M_2\norm{x}_a$ for arbitrary $x$. Hence $\norm{\cdot}_a$ and$\norm{\cdot}_c$ are equivalent.
	\end{pf}
	\begin{pf}{STEP II}{}
		Now let us assume that $\norm{\cdot}_a$ is equivalent to $\norm{\cdot}_b$ on $U_a=\{s\in X:\norm{s}_a=1\}$.
		Then let $x\in X$ be non-zero. Then we have
		$$
			m\norm{\frac{x}{\norm{x}_a}}_a\leq \norm{\frac{x}{\norm{x}_a}}_b\leq M\norm{\frac{x}{\norm{x}_a}}_a
		$$
		So
		$$
			m\norm{x}_a\frac{1}{\norm{x}_a}\leq \norm{x}_b\frac{1}{\norm{x}_a}\leq M\norm{x}_a\frac{1}{\norm{x}_a}
		$$
		And since ${\norm{x}_a}$ is non-zero,we have that
		$$
			m{\norm{x}_a}\leq \norm{x}_b\leq M\norm{x}_a
		$$
		Now since $x$ is arbitrary, the proof is completed.	
	\end{pf}
	\begin{pf}{STEP III}{}
		Now we shall proof continuity of any norm under $\norm\cdot _1$. This can be done by showing for a sequence $(x_n)$ converging to $x$ under the metric induced by $\norm{\cdot}_1$, the norm if its terms under $\norm{\cdot}_a$ converges to $\norm{x}_a$. So let $(x_n)$ be a sequence in $X$ with $x_n\xrightarrow[]{n\to \infty}x$. We have
		\begin{equation}
			\begin{split}\nonumber
				|\norm{x_n}_a-\norm{x}_a|&\leq\norm{x_n-x}_a\leq M\norm{x_n-x}_1\to0\quad \text{when}\,\,n\to\infty
			\end{split}
		\end{equation}
		Thus
		$$
			\lim_{n\to\infty}|\norm{x_n}_a-\norm{x}_a|=0
		$$
	\end{pf}
\begin{pf}{STEP IV}{}
	Now we shall apply extreme value theorem to obtain our final result here. Using the theorem requires unit sphere to be a compact set. Proof of this fact is given later, one should realise that the proof does not depend on equivalence of norms, as we only require compactness in $X,\norm{\cdot}_1$. However, it is true that unit sphere is compact under any norm in finite dimensional cases. So we have that $U_1=\{s\in X:\norm{s}_1=1\}$ is compact with  a  function $\norm{\cdot}_a$ continuous on it, so by extreme value theorem it attains maximum $M_U=max\{\norm{x}_a:x\in U_1\}$ and minimum $m_u=min\{\norm{x}_a:x\in U_1\}$ on $U_1$, thus for any $x\in U_1$ we have
	$$
		m_u \norm{x}_1=m_u\leq\norm{x}_a\leq M_u=M_u \norm{x}_1
	$$
	Hence we show that any norm is equivalent to $\norm{\cdot}_1$ on unit sphere.
\end{pf}
By combining the results of the four steps, we finish the proof of the theorem.
\end{theorem}

\begin{remark}\rm\nextline
	The proof is not unique. We can also choose other norms to be the "bridging" norm, say supremum norm which in finite dimensional case becomes the max norm: $\norm{x}\equiv max\{|x_i|\}$. About the meaning of equivalence here, in fact, equivalent norms are equivalent in the sense that they induces same topology, so it is also called "topologically"equivalent. Generally speaking, this means that topological properties such as open, close, compact, convergence, continuity which holds for one norm will hold in its equivalent norms.
\end{remark}
Following results are simple exercises to check statements above.

\begin{proposition}[Equivalence of openness]\rm\nextline
	Open sets in $(X,\norm{\cdot}_a)$ are open in $(X,\norm{\cdot}_b)$ (Following notation in definition of equivalent norms).
	\begin{pf}{}{}
	It suffices to check open balls. Let $B^a_x(r)\equiv\{s\in X:\norm{x-s}_a<r\}$ be open balls with radius $r>0$ centered at $x$, which is an open ball in $(X,\norm{\cdot}_a)$. Choose $p\in B^a_x(r)$, we should show that $\exists \varepsilon>0$ with $B^b_p(\varepsilon)\equiv\{s\in X:\norm{p-s}_b<\varepsilon\}\subset B^a_x(r)$.\\
	By openness of $B^a_x(r)$, we have that $\exists \varepsilon_a>0$ with
	\begin{equation}
		\begin{split}\nonumber
			B^a_p(\varepsilon_a)&\equiv\{s\in X:\norm{p-s}_a<\varepsilon_a\}\\
			&=\{s\in X:m\norm{p-s}_a<m\varepsilon_a\}\\
			&\supseteq \{s\in X:\norm{p-s}_b<m\varepsilon_a\}\\
			&=B^b_p(m\varepsilon_a)
		\end{split}
	\end{equation}
	Note that $B^b_p(m\varepsilon_a)\subseteq B^a_p(\varepsilon_a)\subset B^a_x(r)$, hence $\varepsilon=m\varepsilon_a$.
	\end{pf}
	
\end{proposition}


\subsection{Subspace of Normed linear space}
As shown previously, finite dimensional vector spaces are all complete (we will assume that the fields of vector spaces are complete, $\real$ or $\comp$). This is also true for finite dimensional subspace of normed linear spaces. Note that we don't need the space to be complete when asserting completeness of their finite dimensional subspace.
\begin{proposition}
	[Completeness of finite-dimensional subspace]\rm\nextline
	Let $(x,\norm{\cdot})$ be a normed linear space. Then a linear subspace $Y\subset X$ with $dim(Y)<\infty$ endowed with $\norm{\cdot}$ induced in $Y$ is a Banach space.
\end{proposition}
Also, we have closedness of finite-dimensional subspace.
\begin{proposition}
	[Closedness of finite-dimensional subspace]\rm\nextline
	Let $(x,\norm{\cdot})$ be a normed linear space. Then a linear subspace $Y\subset X$ with $dim(Y)<\infty$ endowed with $\norm{\cdot}$ induced in $Y$ is closed.
\end{proposition}
Proof of this two proposition is simple use of the results of finite dimensional normed linear spaces begin Banach, which is left to readers. We shall now take a look at few examples showing different subspaces of normed vector spaces.

\begin{example}[Finite-dim subspace being complete]\rm\nextline
	\placeholder
\end{example}

\begin{example}[Infinite-dim subspace not complete]\rm\nextline
	Consider $X=C[0,2]\subset L^1 [0,2]$, set of all real-valued continuous function on $[0,1$, endowed with 1-norm: $\norm{f}_1=\int_0^1|f(t)|dt$. Consider sequence of function $(f_n)$:
	\begin{equation}
		f_n(t)=\left\{
		\begin{aligned}\nonumber
			 & t^n & 0\leq t<1     \\
			 & 1   & 1\leq t\leq 2
		\end{aligned}
		\right.
	\end{equation}
	Now $f_n$ is Cauchy in 1-norm, but its limit is not in $C[0,1]$:
	\begin{equation}
		f(t)=\left\{
		\begin{aligned}\nonumber
			 & 0 & 0\leq t<1     \\
			 & 1 & 1\leq t\leq 2
		\end{aligned}
		\right.
	\end{equation}
	Thus X is not a complete subspace of $L^1[0,2$, as we have a Cauchy sequence that does not converge to a point in $X$.
\end{example}

\begin{example}[Completeness depends on choice of norm]\rm\nextline
	We continue considering the settings in our last example, but endow $X$ with supremum norm: $\norm{\cdot}_\infty$. Now our $(f_n)$ is no longer Cauchy. One can prove that $(X,\norm{\cdot}_\infty$ is actually complete. Intuitively, supremum norm is sensitive to "discontinuity at points", so convergence in supremum norm ensures no "jump" of value at any point.
\end{example}
\newpage

\newpage
\subsection{Fixed point}
Contraction mapping theorem, sometimes called Banach fixed point theorem, guarantees the existence and uniqueness of fixed points of certain self-maps of metric spaces, and provides a constructive method to find those fixed points.

\begin{theorem}[Fixed point]\rm \nextline
	Let $X$ be Banach space, $f:X\xrightarrow{}X$ is a contraction mapping, i.e. a mapping satisfying
	$
		d(f(x),f(y))\leq qd(x,y),\,\forall x,y\in X,
	$
	where $q<1$ is a fixed constant.
	Then $f$ admits a unique fixed point $x^*\in X$, which can be found by
	defining sequence ${x_n}$ in $X$, with $x_{n+1}=f(x_n)$, then $\lim_{n\to \infty}x_n=x^*$\\
	\textit{proof}:\\
	By assumption, we have $\norm{x_n+1-x_n}=\norm{f(x_n)-f(x_{n+1})}\leq q\norm{x_n-x_{n+1}}$.\\
	So if we let $k=\norm{x_2-x_1}/q$, we have that $\norm{x_{n+1}-x_n}\leq k q^n$ with $q<1$.
	This sequence is clearly Cauchy. To see this, choose $m,n\in\mathbb{N}$ with $m<n$
	\begin{equation}
		\begin{split}
			\norm{x_m-x_n}&\leq\sum_{i=m}^{n-1} \norm{x_{i+1}-x_i}\\
			&\leq\sum_{i=m}^{n-1} k q^i\\
			&=\frac{kq^{m} (1-q^{(n-m)})}{1-q}\\
			&< \frac{kq^{m}}{1-q}\\
			%        &=kq^m\sum_{i=0}^{n-m-1} q^i\\
		\end{split}
	\end{equation}
	Fix $\varepsilon>0$, we can find large  $N$ so that

	$$
		q^N\leq \frac{\varepsilon(1-q)}{k}
	$$
	Then for all $m,n>N$ we have
	$$
		\norm{x_m-x_n}<\frac{kq^{m}}{1-q}<\frac{\varepsilon(1-q)}{k}\frac{k}{1-q}=\epsilon
	$$
	Hence ${x_n}$ is Cauchy, thus convergent to a unique point $x^*\in X$
\end{theorem}

\begin{remark}\rm\nextline
	This theorem is easy to prove, however it's very useful. We may see examples of fixed point by playing with calculator: choose any real number and calculate its $\cos$ value, and continue input the result to $cos$, we may find that the result become stable around $0.7390......$. This is a fixed point of $cos$. $sin$ also has fixed point, which is zero. It can be used to give sufficient condition where Newton method for finding root converges. In study of ODE contraction mapping can be used to guarantee that Picard iteration converges to a certain function. See \href{https://en.wikipedia.org/wiki/Picard–Lindelöf_theorem}{Picard–Lindelöf theorem} on Wikipedia.
\end{remark}
\subsection{Exam}
\subsubsection{Proof of completeness}
Generally there are three steps in proving completeness.
\begin{itemize}
	\item Find a candidate for the "limit" of a Cauchy sequence.
	\item Show that it's indeed the "limit'.
	\item Show that it's still in the space.
\end{itemize}

\newpage
\section{Hilbert Space}  

\begin{unexaminable}
Hilbert space is a special class of Banach space. Apart from completeness and norm, it is also equipped with an additional structure, {\bf inner product}. This allow us to explore nice geometric properties of the space,like orthogonality and angle. We'll see later that this structure resemble Euclidean space in many ways. A Hilbert space is naturally Banach, while the reverse may not be true.
\end{unexaminable}

In this section we work with linear space $H$ over $\mathbb{K} = \real \ \textrm{or} \ \mathbb{ C}$

\begin{definition}
(Bilinear Map)
	Let $X$ be a vector space over $\mathbb C$. An {\bf bilinear map} is a function $\left<\cdot,\cdot\right>:H \times H \xrightarrow{}{\mathbb C}$ satisfying following: $\forall x,y,z\in H,\alpha$ a scalar,
	\begin{itemize}
		\item[1] $\left<x,y\right>={\overline{\left<y,x\right>}},\forall x,y\in H$
		\item[2] $\left<x,x\right>\geq0$
		\item[3] $\left<x,x\right>=0$ iff $x=0$
		\item[4] $\left<x+y,z\right>=\left<x,z\right>+\left<y,z\right>$
		\item[5] $\left<ax,z\right>=a\left<x,z\right>$
	\end{itemize}
\end{definition}
1 is complex conjugation. 2 and 3 is positive-definiteness. 4 and 5 is left-linearity.


\begin{theorem}
	If $\left<\cdot,\cdot\right>$ is an inner product on $X$, define $\norm{x}\overset{\textrm{def}}{=}\sqrt{\inne{x}{x}}$.  
	\begin{enumerate}[i)]
	    \item (Cauchy-Schwarz) $\ \forall x,y\in X$,
	$$|\left<x,y\right>|^2\leq\left<x,y\right>\cdot\left<y,y\right>$$
	\item $\norm{x}$ is a norm
\end{enumerate}  
\end{theorem}

\begin{proof}
\begin{enumerate}[i)]
    \item If $x=0$ or $y=0$, the inequality holds. Else, let $\xi = \frac{x}{\norm{x}}, \eta = \frac{y}{\norm{y}}$, so $\norm{\xi}=\norm{\eta}=1$. Hence 
    $$0 \leq \norm{\eta-\inne{\xi}{\eta}\xi}^2=\norm{\eta}^2 - |\inne{\xi}{\eta}|^2=1-|\inne{\xi}{\eta}|^2$$  
    so $|\inne{\xi}{\eta}| \leq 1$
    \item Positivity and homogeneity follows from definition of $\inne{\cdot}{\cdot}$; and triangle inequality follows from i)  
    $$\norm{x+y}^2$$
\end{enumerate}
\end{proof}

\begin{definition}
(Hilbert space)
    An inner product space $(H, \inne{\cdot}{\cdot})$ which is complete w.r.t. the metric induced by $\norm{\cdot}=\sqrt{\inne{\cdot}{\cdot}}$ is called a \textbf{Hilbert space}
\end{definition}


\begin{unexaminable}
\begin{example}[Euclidean Space over $\mathbb R$]\rm\nextline
	It happens that 2-D or 3-D vector space over $\mathbb R$ is an example of Hilbert space, under the standard definition of vector inner product.
\end{example}

\begin{example}[Euclidean Space over $\mathbb C$]\rm\nextline
	${\mathbb C}^n$ with inner product
	$$
		\inne{x}{y}=\sum_{i=1}^n {\overline{x_i}}\,y_i
	$$
	is a Hilbert space. This is a generalization of last example. Still, this is a finite-dimensional Hilbert space.
\end{example}
\end{unexaminable}


\begin{example}[Sequence space]\rm\nextline
	Complex sequence space:
	$$\ell^2=
		\left\{\{x_n\}_1^\infty:\sum_{k=1}^\infty |x_k|^2<\infty \right\}$$
	with  inner product,denoting $x=\{x_n\}_1^\infty$ and $y=\{y_n\}_1^\infty$
	$$
		\inne{x}{y}=\sum_{k=1}^\infty \,{\overline{x_k}\, y_k}
	$$
\end{example}

\begin{unexaminable}
Structure of inner product allows discussion for nice geometric property of Hilbert spaces. This includes orthogonality, angles and nearest distance etc.
\end{unexaminable}
\begin{unexaminable}
Orthogonality is the generalization of two lines being perpendicular. In euclidean geometry, we have Pythagorean theorem closely related to such property. Results on orthogonality in Hilbert spaces in many ways resemble their Euclidean version.
\end{unexaminable}

\begin{proposition}
(Nearest Point Property)
	Let \hbs be a Hilbert space, $K\subset \hbp$ be a closed, convex subset, then $\forall y \in \hbp$ there exists a {\bf{unique}} $x_0\in K$ such that
	$$
		\delta \overset{\rm{def}}{=} \inf_{x\in K} \norm{x-y} = \norm{x_0-y}
	$$
\end{proposition}

\begin{proof} 
By considering the set $K-y = \{x-y: x\in K\}$ (still closed and convex), we can assume $y=0$.  

\underline{\textbf{Existence:}}
By definition of $\delta$, $\exists (x_n)_{n \in \natu}$, $x_n\in K$ such that $\lim_{n \to \infty} \norm{x_n}=\delta$. We show that $(x_n)_{n \in \natu}$ is a Cauchy sequence. Let $\epsilon >0$. Pick $N \in \natu$ such that  

$$
\forall n \geq N \qquad \norm{x_n}^2 < \delta^2 + \frac{\varepsilon^2}{4}
$$  

$K$ being convex implies that $\frac{x_n+x_n}{2} \in K, \forall n,m \in \natu$, which implies by definition of $\delta$, $\norm{x_n+x_m} \geq 2\delta$.  

It follows that for all $n,m \geq N$,  

\begin{equation*}
    \norm{x_n-x_m}^2 = \underbrace{2(\norm{x_n}^2+\norm{x_m}^2)}_{< 2\delta^2 + \varepsilon^2 /2} \underbrace{-\norm{x_n+x_m}^2}_{\leq 4\delta^2} < \varepsilon^2
\end{equation*}  

where we have used the Parallelogram law.  

By completeness, $\exists x_0 \ $ s.t. $x_k \to x_0$ as $k \to \infty$. Since $K$ is closed, the limit $x_0\in K$, and $\norm{x_0}=\delta$ by continuity of the norm $\norm{\cdot}$.  

\underline{\textbf{Uniqueness:}}
\todo{uniqueness}
\end{proof}  

\begin{corollary}
(Orthogonal Decomposition) Let $H$ be a Hilbert space and $E \subset H$ be a closed subspace. Then  

$$
H = E \oplus E^{\perp}
$$  
(\textit{i.e.} $E \cap E^{\perp} = \{0\}$ and $H = E + E^{\perp}$, that is $\forall x \in H, x=e+ e^{\perp}$ for some $e \in E, e^{\perp} \in E^{\perp}$)
\end{corollary}

\begin{proof}
If $x \in E\cap E^{\perp}$, then $\inne{x}{x}=0$, so $\norm{x}=0$, $x=0$.  

For all $x\in H$, $E$
\end{proof}

\begin{definition}[Orthogonality]\rm\nextline
	Let $\mathscr{H}$ be a Hilbert space and $f\in\mathscr{H}$. Say $g$ is orthogonal to $f$ if $\inne{f}{g}=0$, writes $f\perp g$. For two sets $A,B\in \mathscr{H}$, write $A\perp B$ if $a\perp b$ for all $a\in A$ and $b\in B$


\end{definition}

\begin{definition}[Orthogonal Complement]\rm\label{ortho comp}\nextline
	Let $A$ be a set in Hilbert space $\mathscr{H}$. Its orthogonal complement, $A^{\perp}$ is the set of all vectors $f \in \mathscr{H}$ such
	that $f\perp g\,,\forall g \in A$. $A^\perp$ is always a subset of $\mathscr{H}$. Moreover, $A^\perp=\cup_{a\in A}(a)^\perp$, and we can prove that $A^\perp$ is always a closed subset of \hbs.
\end{definition}

\begin{proposition}[Pythagorean Theorem]\rm\nextline
	Let $f_1,\,f_2,\,......,f_n$ be pairwise orthogonal vectors in Hilbert space \hbs. Then
	$$
		\norm{\sum_{k=1}^n f_k}^2={\sum_{k=1}^n \norm{f_k}^2}
	$$
	\textit{proof:}\\
	It suffices to show for n=2, and proceed with induction. Consider $a,b\in \hbp$ with $a\perp b$.
	Then
	\begin{equation}
		\begin{split}
			\norm{a+b}^2&=\inne{a+b}{a+b}\\
			&=\inne{a}{a}+\inne{a}{b}+\inne{b}{a}+\inne{b}{b}\\
			&=\inne{a}{a}+0+0+\inne{b}{b}\\
			&=\norm{a}^2+\norm{b}^2
		\end{split}
	\end{equation}


\end{proposition}

\begin{remark}[Parallelogram equality]\rm\label{parallelogram}\nextline
	Let $a,b\in \hbp$ be arbitrary vectors.
	Then
	\begin{equation}
		\begin{split}
			\norm{a+b}^2&=\inne{a+b}{a+b}\\
			&=\inne{a}{a}+\inne{a}{b}+\inne{b}{a}+\inne{b}{b}\\
			&=\inne{a}{a}+\inne{a}{b}+{\overline{\inne{a}{b}}}+\inne{b}{b}\\
			&=\norm{a}^2+2Re(\inne{a}{b})+\norm{b}^2
		\end{split}
	\end{equation}

	Similarly,
	\begin{equation}
		\begin{split}
			\norm{a-b}^2&=\inne{a-b}{a-b}\\
			&=\inne{a}{a}-\inne{a}{b}-\inne{b}{a}+\inne{b}{b}\\
			&=\inne{a}{a}-\inne{a}{b}-{\overline{\inne{a}{b}}}+\inne{b}{b}\\
			&=\norm{a}^2-2Re(\inne{a}{b})+\norm{b}^2
		\end{split}
	\end{equation}

	Adding up, we obtain {\bf{\emph{ parallelogram equality}}}:
	$$
		\norm{a+b}^2+\norm{a-b}^2=2\norm{a}^2+2\norm{b}^2
	$$


	This equation holds for all Hilbert spaces including 2-d vector space over $\mathbb R$. Readers may find this form identical to the parallelogram equality in that vector space. It is also where the name comes from.
\end{remark}



\subsubsection{Nearest Point Property}
\begin{unexaminable}
In Euclidean geometry, choosing a point and a line we can find the minimal distance form the point to any point on the line, defined as the distance from the point to the line. This can be generalized, with line extending to a {\bf{\emph{closed convex set}}} and space becoming a Hilbert space.
\end{unexaminable}


\begin{definition}[Convexity]\rm\label{convexity}\nextline
	A set $S\subset \mathscr{H}$ is convex if $\forall f,g\in S,\forall t\in\left[0,1\right]$, we have $(tf+(1-t)g)\in S$.

\end{definition}
Intuitively, this means that given any two points in the a convex set, the "segment" connecting the points stays inside the set. Hence a closed convex set is such a set with the property that every convergent sequence in the set converges to a point in the set.

\begin{definition}[Set-point distance]\rm\nextline
	Let \hbs be a Hilbert space, $S\in \mathscr{H}$ be a closed subset, $x\in \hbp$ be arbitrary vector. We define the {\bf{distance}} from $x$ to $S$ to be the infimum of distance between $x$ and element of $S$:

	$$\text{dist}(S,x)\equiv\inf_{s\in S} (\norm{s-x})$$

\end{definition}




\subsubsection{Projection Theorem}
\begin{definition}[Projection mapping]\rm\nextline
	Let \hbs be a Hilbert space. A mapping $P:\hbp\xrightarrow{}\hbp$ is a projection mapping if $$
		P(Px)=Px,\,\forall x\in\hbp
	$$


\end{definition}


\begin{proposition}[Projection Theorem]\rm\nextline
	Let \hbs be a Hilbert space and M a closed subspace. Then there exists unique pair of projection mapping $P:\hbp\xrightarrow{}M$ and $Q:\hbp\xrightarrow{}M^\perp$ satisfying $x=Px+Qx$ for any $x\in\hbp$, with the following property:
	\begin{enumerate}[(1)]
		\item $x\in M$ if and only if $Px=x,\,Qx=0$
		\item $x\in M^\perp$ if and only if $Px=0,\,Qx=x$
		\item $\norm{Px}^2+\norm{Qx}^2=\norm{x}^2$
		\item $P$ and $Q$ are linear maps
		\item $Px$ is the closest vector in $M$ to x.
		\item $Qx$ is the closest vector in $M^\perp$ to x.
	\end{enumerate}
	\textit{proof:}\\
	We shall use nearest point property. Since $M$ is a closed subspace, it is clearly a convex subset of \hbs. Thus for each $x\in \hbp$ there exists a unique point in $M$ that is closest to $x$. So we define $Px$ to be the unique nearest point in $M$ for each x. Uniqueness of nearest point gives the uniqueness of mapping $P$. $Q$ is then defined as $x-Px$. We should show that this definition of $Q$ indeed gives a mapping from \hbs to $M^\perp$.\\
	Fix $x$, let $m\in M$ be such that $\norm{m}=1$. We must have, for all $a\in\mathbb{C}$:
	\begin{equation}
		\begin{split}
			\norm{Qx}^2&\leq\norm{Qx+am}^2\\
			&=\norm{Qx}^2+|a|^2\norm{m}^2+\inne{Qx}{m}+\inne{m}{Qx}
		\end{split}
	\end{equation}
	Then we choose $a=-\inne{Qx}{m}$ and simplify the equation, we have
	\begin{equation}
		\begin{split}
			0&\leq|a|^2\norm{m}^2+\inne{Qx}{am}+\inne{am}{Qx}\\
			&=|\inne{Qx}{m}|^2\norm{m}^2+\inne{Qx}{-\inne{Qx}{m}m}+\inne{-\inne{Qx}{m}m}{Qx}\\
			&=|\inne{Qx}{m}|^2-
			\overline{\inne{Qx}{m}}\inne{Qx}{m}-
			\overline{\inne{m}{Qx}}\inne{m}{Qx}\\
			&=-|\inne{Qx}{m}|^2
		\end{split}
	\end{equation}
	Thus we must have $\inne{Qx}{m}=0$, so $Qx\in M^\perp$.\\
	We proceed to prove (1) and (2).\\
	First $x\in M$. We have $Qx\in M^\perp$. Note that $x\in M$ and $Px\in M$ we have $Qx=x-Px\in M$. Hence $Qx\in(M\cap M^\perp)={0}$. Thus $Qx=0$ and $Px=x-0=x$. \\
	To see other direction, we simply notice that $x=Px\in M$ by definition.\\
	Proof of (2) is similar.\\
	Now let's prove (3). We shall use the fact that $Px\perp Qx$, giving $\inne{Px}{Qx}=0$
	\begin{equation}
		\begin{split}
			\norm{x}^2&=\inne{x}{x}\\
			&=\inne{Px+Qx}{Px+Qx}\\
			&=\inne{Px}{Px}+\inne{Qx}{Px}+\inne{Px}{Qx}+\inne{Qx}{Qx}\\
			&=\inne{Px}{Px}+\inne{Qx}{Qx}\\
			&=\norm{Px}^2+\norm{Qx}^2
		\end{split}
	\end{equation}
	Proof of (4) is a routine work verifying linearity. Left as an exercise.\\
	Now let's prove (5) and (6).\\
	(3) is given by the construction of P. To see (4), consider $y\in M^\perp$, we have:
	$$
		\norm{x-y}=\norm{Px+Qx-y}=\norm{Px}+\norm{Qx-y}\geq \norm{Px}
	$$
	So minimal distance is $\norm{Px}$, Obtained at $y=Qx$
\end{proposition}

\end{document}